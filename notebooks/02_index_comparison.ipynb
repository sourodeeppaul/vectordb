{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Comparison Guide\n",
    "\n",
    "This notebook compares different indexing algorithms available in VectorDB and helps you choose the right one for your use case.\n",
    "\n",
    "## Index Types\n",
    "\n",
    "| Index | Best For | Speed | Recall | Memory |\n",
    "|-------|----------|-------|--------|--------|\n",
    "| **Flat** | Small datasets (<10k) | ⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ |\n",
    "| **IVF** | Medium datasets | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ |\n",
    "| **HNSW** | General purpose | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐ |\n",
    "| **PQ** | Large datasets, memory constrained | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vectordb import VectorDatabase\n",
    "from vectordb.index import FlatIndex, IVFIndex, HNSWIndex, ProductQuantizationIndex\n",
    "\n",
    "# For computing ground truth\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "N_VECTORS = 10000  # Number of vectors in the database\n",
    "N_QUERIES = 100    # Number of query vectors\n",
    "DIMENSION = 128    # Vector dimension\n",
    "K = 10             # Number of neighbors to retrieve\n",
    "\n",
    "# Generate random vectors\n",
    "print(f\"Generating {N_VECTORS} database vectors...\")\n",
    "data = np.random.randn(N_VECTORS, DIMENSION).astype(np.float32)\n",
    "\n",
    "print(f\"Generating {N_QUERIES} query vectors...\")\n",
    "queries = np.random.randn(N_QUERIES, DIMENSION).astype(np.float32)\n",
    "\n",
    "# Generate IDs\n",
    "ids = [f\"vec_{i}\" for i in range(N_VECTORS)]\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Queries shape: {queries.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Ground Truth\n",
    "\n",
    "We'll use brute-force search to compute the true nearest neighbors for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ground_truth(data: np.ndarray, queries: np.ndarray, k: int) -> np.ndarray:\n",
    "    \"\"\"Compute exact k-nearest neighbors using brute force.\"\"\"\n",
    "    distances = cdist(queries, data, metric='euclidean')\n",
    "    indices = np.argsort(distances, axis=1)[:, :k]\n",
    "    return indices\n",
    "\n",
    "def compute_recall(predicted: List[List[int]], ground_truth: np.ndarray, k: int) -> float:\n",
    "    \"\"\"Compute recall@k.\"\"\"\n",
    "    recalls = []\n",
    "    for pred, gt in zip(predicted, ground_truth):\n",
    "        pred_set = set(pred[:k])\n",
    "        gt_set = set(gt[:k].tolist())\n",
    "        recall = len(pred_set & gt_set) / k\n",
    "        recalls.append(recall)\n",
    "    return np.mean(recalls)\n",
    "\n",
    "print(\"Computing ground truth...\")\n",
    "ground_truth = compute_ground_truth(data, queries, K)\n",
    "print(f\"Ground truth shape: {ground_truth.shape}\")\n",
    "print(f\"Sample ground truth for query 0: {ground_truth[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Flat Index (Brute Force)\n",
    "\n",
    "The Flat index performs exact nearest neighbor search by comparing the query to every vector in the database.\n",
    "\n",
    "**Pros:**\n",
    "- 100% recall (exact results)\n",
    "- No training required\n",
    "- Simple and reliable\n",
    "\n",
    "**Cons:**\n",
    "- O(n) search time\n",
    "- Too slow for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and build Flat index\n",
    "print(\"Building Flat index...\")\n",
    "flat_index = FlatIndex(dimension=DIMENSION, metric='euclidean')\n",
    "\n",
    "build_start = time.time()\n",
    "flat_index.add(data, ids=ids)\n",
    "flat_build_time = time.time() - build_start\n",
    "\n",
    "print(f\"Build time: {flat_build_time:.3f}s\")\n",
    "print(f\"Vectors indexed: {flat_index.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Flat index search\n",
    "def benchmark_index(index, queries, k, n_runs=3):\n",
    "    \"\"\"Benchmark search performance.\"\"\"\n",
    "    times = []\n",
    "    all_results = None\n",
    "    \n",
    "    for _ in range(n_runs):\n",
    "        start = time.time()\n",
    "        results = []\n",
    "        for query in queries:\n",
    "            result = index.search(query, k=k)\n",
    "            # Extract indices from results\n",
    "            indices = [int(r['id'].split('_')[1]) for r in result]\n",
    "            results.append(indices)\n",
    "        times.append(time.time() - start)\n",
    "        all_results = results\n",
    "    \n",
    "    return {\n",
    "        'mean_time': np.mean(times),\n",
    "        'std_time': np.std(times),\n",
    "        'qps': len(queries) / np.mean(times),\n",
    "        'results': all_results\n",
    "    }\n",
    "\n",
    "flat_benchmark = benchmark_index(flat_index, queries, K)\n",
    "flat_recall = compute_recall(flat_benchmark['results'], ground_truth, K)\n",
    "\n",
    "print(f\"Flat Index Results:\")\n",
    "print(f\"  Search time: {flat_benchmark['mean_time']:.3f}s (±{flat_benchmark['std_time']:.3f})\")\n",
    "print(f\"  QPS: {flat_benchmark['qps']:.1f}\")\n",
    "print(f\"  Recall@{K}: {flat_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. IVF Index (Inverted File)\n",
    "\n",
    "IVF partitions the vector space into clusters. During search, only a subset of clusters (nprobe) are searched.\n",
    "\n",
    "**Pros:**\n",
    "- Much faster than flat for large datasets\n",
    "- Tunable speed/recall tradeoff (nprobe)\n",
    "\n",
    "**Cons:**\n",
    "- Requires training on data\n",
    "- Lower recall than flat (approximate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and build IVF index\n",
    "N_CLUSTERS = 100  # Number of clusters\n",
    "\n",
    "print(f\"Building IVF index with {N_CLUSTERS} clusters...\")\n",
    "ivf_index = IVFIndex(dimension=DIMENSION, n_clusters=N_CLUSTERS, metric='euclidean')\n",
    "\n",
    "build_start = time.time()\n",
    "ivf_index.train(data)  # IVF requires training\n",
    "ivf_index.add(data, ids=ids)\n",
    "ivf_build_time = time.time() - build_start\n",
    "\n",
    "print(f\"Build time: {ivf_build_time:.3f}s\")\n",
    "print(f\"Vectors indexed: {ivf_index.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark IVF with different nprobe values\n",
    "nprobe_values = [1, 4, 8, 16, 32]\n",
    "ivf_results = []\n",
    "\n",
    "print(\"IVF Index Results:\")\n",
    "print(f\"{'nprobe':>8} {'Time (s)':>10} {'QPS':>10} {'Recall':>10}\")\n",
    "print(\"-\" * 42)\n",
    "\n",
    "for nprobe in nprobe_values:\n",
    "    ivf_index.nprobe = nprobe\n",
    "    benchmark = benchmark_index(ivf_index, queries, K)\n",
    "    recall = compute_recall(benchmark['results'], ground_truth, K)\n",
    "    \n",
    "    ivf_results.append({\n",
    "        'nprobe': nprobe,\n",
    "        'time': benchmark['mean_time'],\n",
    "        'qps': benchmark['qps'],\n",
    "        'recall': recall\n",
    "    })\n",
    "    \n",
    "    print(f\"{nprobe:>8} {benchmark['mean_time']:>10.3f} {benchmark['qps']:>10.1f} {recall:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. HNSW Index (Hierarchical Navigable Small World)\n",
    "\n",
    "HNSW builds a hierarchical graph structure for efficient approximate nearest neighbor search.\n",
    "\n",
    "**Pros:**\n",
    "- Excellent speed/recall tradeoff\n",
    "- No training required\n",
    "- Works well for most use cases\n",
    "\n",
    "**Cons:**\n",
    "- Higher memory usage (stores graph structure)\n",
    "- Slower build time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and build HNSW index\n",
    "M = 16  # Number of connections per node\n",
    "EF_CONSTRUCTION = 100  # Size of dynamic candidate list during construction\n",
    "\n",
    "print(f\"Building HNSW index (M={M}, ef_construction={EF_CONSTRUCTION})...\")\n",
    "hnsw_index = HNSWIndex(\n",
    "    dimension=DIMENSION,\n",
    "    M=M,\n",
    "    ef_construction=EF_CONSTRUCTION,\n",
    "    metric='euclidean'\n",
    ")\n",
    "\n",
    "build_start = time.time()\n",
    "hnsw_index.add(data, ids=ids)\n",
    "hnsw_build_time = time.time() - build_start\n",
    "\n",
    "print(f\"Build time: {hnsw_build_time:.3f}s\")\n",
    "print(f\"Vectors indexed: {hnsw_index.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark HNSW with different ef_search values\n",
    "ef_search_values = [16, 32, 64, 128, 256]\n",
    "hnsw_results = []\n",
    "\n",
    "print(\"HNSW Index Results:\")\n",
    "print(f\"{'ef_search':>10} {'Time (s)':>10} {'QPS':>10} {'Recall':>10}\")\n",
    "print(\"-\" * 44)\n",
    "\n",
    "for ef_search in ef_search_values:\n",
    "    hnsw_index.ef_search = ef_search\n",
    "    benchmark = benchmark_index(hnsw_index, queries, K)\n",
    "    recall = compute_recall(benchmark['results'], ground_truth, K)\n",
    "    \n",
    "    hnsw_results.append({\n",
    "        'ef_search': ef_search,\n",
    "        'time': benchmark['mean_time'],\n",
    "        'qps': benchmark['qps'],\n",
    "        'recall': recall\n",
    "    })\n",
    "    \n",
    "    print(f\"{ef_search:>10} {benchmark['mean_time']:>10.3f} {benchmark['qps']:>10.1f} {recall:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Product Quantization (PQ)\n",
    "\n",
    "PQ compresses vectors by dividing them into subvectors and quantizing each subvector separately.\n",
    "\n",
    "**Pros:**\n",
    "- Significant memory reduction\n",
    "- Fast search on compressed data\n",
    "\n",
    "**Cons:**\n",
    "- Lower recall due to compression\n",
    "- Requires training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and build PQ index\n",
    "N_SUBVECTORS = 16  # Number of subvectors (must divide dimension)\n",
    "N_BITS = 8  # Bits per subvector (256 centroids)\n",
    "\n",
    "print(f\"Building PQ index (n_subvectors={N_SUBVECTORS}, n_bits={N_BITS})...\")\n",
    "pq_index = ProductQuantizationIndex(\n",
    "    dimension=DIMENSION,\n",
    "    n_subvectors=N_SUBVECTORS,\n",
    "    n_bits=N_BITS,\n",
    "    metric='euclidean'\n",
    ")\n",
    "\n",
    "build_start = time.time()\n",
    "pq_index.train(data)\n",
    "pq_index.add(data, ids=ids)\n",
    "pq_build_time = time.time() - build_start\n",
    "\n",
    "print(f\"Build time: {pq_build_time:.3f}s\")\n",
    "print(f\"Vectors indexed: {pq_index.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark PQ index\n",
    "pq_benchmark = benchmark_index(pq_index, queries, K)\n",
    "pq_recall = compute_recall(pq_benchmark['results'], ground_truth, K)\n",
    "\n",
    "print(f\"PQ Index Results:\")\n",
    "print(f\"  Search time: {pq_benchmark['mean_time']:.3f}s\")\n",
    "print(f\"  QPS: {pq_benchmark['qps']:.1f}\")\n",
    "print(f\"  Recall@{K}: {pq_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "summary = [\n",
    "    {'Index': 'Flat', 'Build Time': flat_build_time, 'QPS': flat_benchmark['qps'], 'Recall': flat_recall},\n",
    "    {'Index': 'IVF (nprobe=8)', 'Build Time': ivf_build_time, 'QPS': ivf_results[2]['qps'], 'Recall': ivf_results[2]['recall']},\n",
    "    {'Index': 'HNSW (ef=64)', 'Build Time': hnsw_build_time, 'QPS': hnsw_results[2]['qps'], 'Recall': hnsw_results[2]['recall']},\n",
    "    {'Index': 'PQ', 'Build Time': pq_build_time, 'QPS': pq_benchmark['qps'], 'Recall': pq_recall},\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INDEX COMPARISON SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Index':<20} {'Build Time':>12} {'QPS':>12} {'Recall':>12}\")\n",
    "print(\"-\" * 70)\n",
    "for row in summary:\n",
    "    print(f\"{row['Index']:<20} {row['Build Time']:>12.3f} {row['QPS']:>12.1f} {row['Recall']:>12.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize recall vs QPS tradeoff\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# IVF tradeoff\n",
    "ivf_qps = [r['qps'] for r in ivf_results]\n",
    "ivf_recall = [r['recall'] for r in ivf_results]\n",
    "ax1.plot(ivf_qps, ivf_recall, 'o-', label='IVF', markersize=8)\n",
    "for r in ivf_results:\n",
    "    ax1.annotate(f\"np={r['nprobe']}\", (r['qps'], r['recall']), textcoords=\"offset points\", xytext=(5,5))\n",
    "\n",
    "# HNSW tradeoff\n",
    "hnsw_qps = [r['qps'] for r in hnsw_results]\n",
    "hnsw_recall = [r['recall'] for r in hnsw_results]\n",
    "ax1.plot(hnsw_qps, hnsw_recall, 's-', label='HNSW', markersize=8)\n",
    "for r in hnsw_results:\n",
    "    ax1.annotate(f\"ef={r['ef_search']}\", (r['qps'], r['recall']), textcoords=\"offset points\", xytext=(5,5))\n",
    "\n",
    "# Flat baseline\n",
    "ax1.axhline(y=flat_recall, color='g', linestyle='--', label='Flat (baseline)')\n",
    "\n",
    "ax1.set_xlabel('Queries per Second (QPS)')\n",
    "ax1.set_ylabel(f'Recall@{K}')\n",
    "ax1.set_title('Recall vs Speed Tradeoff')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Build time comparison\n",
    "indices = ['Flat', 'IVF', 'HNSW', 'PQ']\n",
    "build_times = [flat_build_time, ivf_build_time, hnsw_build_time, pq_build_time]\n",
    "ax2.bar(indices, build_times, color=['blue', 'orange', 'green', 'red'])\n",
    "ax2.set_ylabel('Build Time (seconds)')\n",
    "ax2.set_title('Index Build Time Comparison')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Right Index\n",
    "\n",
    "### Decision Guide\n",
    "\n",
    "```\n",
    "Dataset Size?\n",
    "├── < 10,000 vectors → Use FLAT (exact results, fast enough)\n",
    "├── 10k - 1M vectors\n",
    "│   ├── Memory constrained? → Use IVF-PQ\n",
    "│   └── Otherwise → Use HNSW\n",
    "└── > 1M vectors\n",
    "    ├── Need highest recall? → Use IVF-HNSW (hybrid)\n",
    "    └── Memory constrained? → Use IVF-PQ\n",
    "```\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **HNSW** is the best general-purpose index for most applications\n",
    "2. **IVF** is good when you need to tune the speed/recall tradeoff dynamically\n",
    "3. **PQ** is essential when memory is a constraint\n",
    "4. **Flat** is perfect for small datasets or when you need 100% recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **03_performance_tuning.ipynb**: Learn how to tune index parameters for optimal performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}